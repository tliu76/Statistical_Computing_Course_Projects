{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/USCbiostats/PM520/blob/main/Lab_11_Variational_Inference_PtIV.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","source":["# Get Lucky, or: Non-Conjugate Variational Inference Pt II\n","\n","Recall, that  CAVI derivations assume that our surrogate models are the result of conditional conjugacy between the expected log likelihood and the prior.\n","\n","Last week, we _assumed_ that $Q_j(\\theta_j)$ is in the _same_ exponential family as its corresponding prior $\\Pr(\\theta_j)$. We then derived the analytic expectations required for the ELBO and performed gradient ascent.\n","\n","> _What if there are no closed form/analytic solutions for the expectations (i.e. ELBO)_?\n","\n","One solution to this problem, is to leverage _stochastic_ gradient descent by performing Monte Carlo sampling of the necessary gradients."],"metadata":{"id":"jrD68Sr315c_"}},{"cell_type":"markdown","source":["## Why is this a problem? Lemme differentiate under the integral!\n","$$\\begin{align*}\n","\\text{ELBO}(\\theta) &:= \\mathbb{E}_Q\\left[\\log \\Pr(\\mathbf{X} | \\mathbf{z})\\right] - \\mathsf{D}_{KL}(Q(\\mathbf{z})||P(\\mathbf{z}))\\\\\n","\\nabla_{\\theta}\\text{ELBO}(\\theta) &=\n","  \\nabla_{\\theta}\\mathbb{E}_Q\\left[\\log \\Pr(\\mathbf{X} | \\mathbf{z})\\right]\n","  -\\underbrace{\\nabla_{\\theta}\\mathsf{D}_{KL}(Q(\\mathbf{z})||P(\\mathbf{z}))}_{\\text{typically analytically tractable!}}\\\\\n","\\nabla_{\\theta}\\mathbb{E}_Q\\left[\\log \\Pr(\\mathbf{X} | \\mathbf{z})\\right] &= \\nabla_{\\theta}\\int Q_{\\theta}(\\mathbf{z})\\log \\Pr(\\mathbf{X} | \\mathbf{z}) d\\mathbf{z}\\\\\n","  &= \\int \\nabla_{\\theta}Q_{\\theta}(\\mathbf{z})\\log \\Pr(\\mathbf{X}|\\mathbf{z})d \\mathbf{z} \\\\\n","  &\\neq \\mathbb{E}_{Q}\\left[\\nabla_{\\theta} \\log \\Pr(\\mathbf{X} | \\mathbf{z})\\right]\n","\\end{align*}$$\n","\n","\n","Our expectation depends on the parameters $\\theta$, which complicates our expression, and typically doesn't result in a known closed form solution. Additionally, by the straightforward derivation above, we see that we can't sample gradients directly as it isn't the same expression!\n","\n","> _What gives?_\n","\n","## Reparameterization Trick\n","If we can define $\\mathbf{z}$ as a _deterministic_ function $g_{\\theta}(ɛ) \\mapsto \\mathbf{z}$, then we may be able to circumvent this issue. For _location-scale_ families $f$, this is trivial! Namely, $\\mathbf{z} = \\mu + \\sigma \\circ ɛ$, where $ɛ_j \\sim f(0, 1)$, $\\theta = \\{\\mu, \\sigma\\}$. Now we have gone from $\\mathbb{E}_{Q}\\left[ \\log \\Pr(\\mathbf{X} | \\mathbf{z}) \\right]$ to $\\mathbb{E}_{ɛ \\sim f(0, 1)}\\left[ \\log \\Pr(\\mathbf{X} | g_{\\theta}(ɛ))\\right]$.\n","\n","> _How does this help us?_\n","\n","We can use Monte-Carlo estimates of the gradient under this reparameterization to approximate the exact gradient. This can be\n","shown by,\n","$$\\begin{align*}\n","\\nabla_{\\theta}\\mathbb{E}_Q\\left[\\log \\Pr(\\mathbf{X} | \\mathbf{z})\\right] &=\n","  \\nabla_{\\theta}\\mathbb{E}_{ɛ \\sim f(0, 1)}\\left[ \\log \\Pr(\\mathbf{X} | g_{\\theta}(ɛ))\\right] \\\\\n","&= \\nabla_{\\theta} \\int f(ɛ) \\log \\Pr(\\mathbf{X} | g_{\\theta}(ɛ)) dɛ\\\\\n","&= \\int f(ɛ) \\nabla_{\\theta}\\log \\Pr(\\mathbf{X} | g_{\\theta}(ɛ)) dɛ\\\\\n","&= \\mathbb{E}_{ɛ \\sim f(0, 1)}\\left[\\nabla_{\\theta}\\log \\Pr(\\mathbf{X} | g_{\\theta}(ɛ)) \\right] \\\\\n","&\\approx \\dfrac{1}{T} \\sum_{t=1}^T \\nabla_{\\theta}\\log \\Pr(\\mathbf{X} | g_{\\theta}(ɛ^t)),\n","\\end{align*}$$\n","where $ɛ^t \\sim f(0, 1)$.\n"],"metadata":{"id":"pMTNVVCP8Cnu"}},{"cell_type":"markdown","source":["## Lab: Logistic Regression with Normal priors on effects\n","We would like to perform variational inference under the following model:\n","$$\\begin{align*}\n","\\mathbf{y}_i | \\beta &\\sim \\text{Bernoulli}(\\text{sigmoid}(\\mathbf{x}_i^T \\beta))\\\\\n","\\beta_j &\\sim N(0, \\sigma^2_b).\n","\\end{align*}$$\n","\n","\n","Let's assume $Q(\\beta) = \\prod_{j=1}^p Q_j(\\beta_j) = N(\\beta_j | \\mu_j, \\sigma^2_j)$. This model doesn't exhibit (any known) closed-form expectations, so we must rely on stochastic optimization. Let's code the reparameterization trick to optimize the ELBO for this model."],"metadata":{"id":"lu-DHtx0Wku7"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"BiGZ0RfieKCk"},"outputs":[],"source":["import operator as op\n","\n","from typing import NamedTuple\n","\n","import jax\n","import jax.random as rdm\n","import jax.nn as nn\n","import jax.numpy as jnp\n","import jax.scipy as jsp\n","\n","from jax import Array\n","from jax.tree_util import tree_map, tree_reduce\n","from jax.typing import ArrayLike\n","\n","from jax import config\n","config.update(\"jax_enable_x64\", True)\n","\n","\n","class PriorParams(NamedTuple):\n","  mean_b: Array\n","  var_b: Array\n","\n","\n","class PosteriorParams(NamedTuple):\n","  mean_b: Array\n","  log_var_b: Array\n","\n","\n","def _kl_divergence(post: PosteriorParams, prior: PriorParams) -> Array:\n","  var_b = jnp.exp(post.log_var_b)\n","\n","  term1 = ((post.mean_b - prior.mean_b) ** 2) / prior.var_b\n","  term2 = var_b / prior.var_b\n","  term3 = post.log_var_b - jnp.log(prior.var_b)\n","  return 0.5 * (term1 + term2 - term3 - 1)\n","\n","\n","def kl_divergence(post: PosteriorParams, prior: PriorParams) -> float:\n","  \"\"\"KL divergence for scalar normals\n","  \"\"\"\n","  return jnp.sum(_kl_divergence(post, prior))\n","\n","\n","def complete_log_likelihood(y: ArrayLike, X: ArrayLike, beta: Array) -> float:\n","  \"\"\" log-likelihood of binary outcomes y, given X, beta\n","  \"\"\"\n","  eps = jnp.finfo(beta.dtype).eps\n","  probs = jnp.clip(nn.sigmoid(X @ beta),\n","                   eps,\n","                   1. - eps,\n","  )\n","  return jnp.sum(jsp.stats.bernoulli.logpmf(y, probs))\n","\n","\n","def sample_log_likelihood(post: PosteriorParams, y: ArrayLike, X: ArrayLike, key: ArrayLike) -> float:\n","  n, p = X.shape\n","  # reparameterization trick\n","  std_dev_b = jnp.exp(0.5 * post.log_var_b)\n","  beta = post.mean_b + std_dev_b * rdm.normal(key, shape=(p,))\n","  return complete_log_likelihood(y, X, beta)\n","\n","\n","def elbo(post: PosteriorParams, prior: PriorParams, y: ArrayLike, X: ArrayLike, key: ArrayLike) -> float:\n","  e_ll = sample_log_likelihood(post, y, X, key)\n","  kl = kl_divergence(post, prior)\n","  return e_ll - kl\n","\n","\n","def fit(y: ArrayLike, X: ArrayLike, prior_var_b: float = 1e-3, num_samples: int = 5, step_size = 1e-3, seed = 0, max_iter=100) -> PosteriorParams:\n","  #initialize our random keye\n","  n, p = X.shape\n","  key = rdm.PRNGKey(seed)\n","\n","  # split to initalize our variational parameters\n","  key, init_mean_key = rdm.split(key, 2)\n","  post = PosteriorParams(\n","      mean_b = jnp.sqrt(prior_var_b) * rdm.normal(init_mean_key, (p,)),\n","      log_var_b = jnp.log(prior_var_b * jnp.ones((p,))),\n","  )\n","  prior = PriorParams(\n","      mean_b = jnp.zeros((p,)),\n","      var_b = prior_var_b * jnp.ones((p,)),\n","  )\n","\n","  # sample gradient using reparam trick for expected log like\n","  def _step(post, key): # value of the elbo and the gradient with respect to all variational parameters\n","    elboval, elboggrad = jax.value_and_grad(elbo)(post, prior, y, X, key)\n","\n","    return elboval, elboggrad\n","\n","  for epoch in range(max_iter):\n","    key, *skey = rdm.split(key, num_samples + 1)\n","    skey = jnp.array(skey)\n","    evals, grads = jax.vmap(_step, (None, 0,))(post, skey)\n","    elboval = jnp.mean(evals)\n","    grad = PosteriorParams(mean_b = jnp.mean(grads.mean_b, axis=0),\n","                           log_var_b = jnp.mean(grads.log_var_b, axis=0))\n","\n","    print(f\"ELBO[{epoch}] ≈ {elboval}\")\n","    post = tree_map(lambda _post, _grad: _post + step_size * _grad, post, grad)\n","    #print(f\"params = {post}\")\n","    # sample to -compute/evaluate- the ELBO\n","\n","  return post"]},{"cell_type":"markdown","source":["#New:"],"metadata":{"id":"nAv1t61Hwzmi"}},{"cell_type":"code","source":["import operator as op\n","\n","from typing import NamedTuple\n","\n","import jax\n","import jax.random as rdm\n","import jax.nn as nn\n","import jax.numpy as jnp\n","import jax.scipy as jsp\n","\n","from jax import Array\n","from jax.tree_util import tree_map, tree_reduce\n","from jax.typing import ArrayLike\n","\n","from jax import config\n","config.update(\"jax_enable_x64\", True)\n","\n","\n","class PriorParams(NamedTuple):\n","  mean_b: Array\n","  var_b: Array\n","\n","\n","class PosteriorParams(NamedTuple):\n","  mean_b: Array\n","  log_var_b: Array\n","\n","\n","def _kl_divergence(post: PosteriorParams, prior: PriorParams) -> Array:\n","  var_b = jnp.exp(post.log_var_b)\n","\n","  term1 = ((post.mean_b - prior.mean_b) ** 2) / prior.var_b\n","  term2 = var_b / prior.var_b\n","  term3 = post.log_var_b - jnp.log(prior.var_b)\n","\n","  return 0.5 * (term1 + term2 - term3 - 1)\n","\n","\n","def kl_divergence(post: PosteriorParams, prior: PriorParams) -> float:\n","  \"\"\"KL divergence for scalar normals\n","  \"\"\"\n","  return jnp.sum(_kl_divergence(post, prior))\n","\n","\n","def complete_log_likelihood(y: ArrayLike, X: ArrayLike, beta: Array) -> float:\n","  \"\"\" log-likelihood of binary outcomes y, given X, beta\n","  \"\"\"\n","  eps = jnp.finfo(beta.dtype).eps\n","  probs = jnp.clip(nn.sigmoid(X @ beta),\n","                   eps,\n","                   1. - eps,\n","  )\n","  return jnp.sum(jsp.stats.bernoulli.logpmf(y, probs))\n","\n","\n","def sample_log_likelihood(post: PosteriorParams, y: ArrayLike, X: ArrayLike, key: ArrayLike) -> float:\n","  n, p = X.shape\n","  # reparameterization trick\n","  std_dev_b = jnp.exp(0.5 * post.log_var_b)\n","  beta = post.mean_b + std_dev_b * rdm.normal(key, shape=(p,))\n","  return complete_log_likelihood(y, X, beta)\n","\n","\n","def elbo(post: PosteriorParams, prior: PriorParams, y: ArrayLike, X: ArrayLike, key: ArrayLike) -> float:\n","  e_ll = sample_log_likelihood(post, y, X, key)\n","  kl = kl_divergence(post, prior)\n","  return e_ll - kl\n","\n","\n","def fit(y: ArrayLike, X: ArrayLike, prior_var_b: float = 1e-3, num_samples: int = 5, step_size = 1e-3, seed = 0, max_iter=100) -> PosteriorParams:\n","  #initialize our random keye\n","  n, p = X.shape\n","  key = rdm.PRNGKey(seed)\n","\n","  # split to initalize our variational parameters\n","  key, init_mean_key = rdm.split(key, 2)\n","  post = PosteriorParams(\n","      mean_b = jnp.sqrt(prior_var_b) * rdm.normal(init_mean_key, (p,)),\n","      log_var_b = jnp.log(prior_var_b * jnp.ones((p,))),\n","  )\n","  prior = PriorParams(\n","      mean_b = jnp.zeros((p,)),\n","      var_b = prior_var_b * jnp.ones((p,)),\n","  )\n","\n","  # sample gradient using reparam trick for expected log like\n","  def _step(post, key):\n","    elboval, elboggrad = jax.value_and_grad(elbo)(post, prior, y, X, key)\n","\n","    return elboval, elboggrad\n","\n","  for epoch in range(max_iter):\n","    key, *skey = rdm.split(key, num_samples + 1)\n","    skey = jnp.array(skey)\n","    evals, grads = jax.vmap(_step, (None, 0,))(post, skey)\n","    elboval = jnp.mean(evals)\n","    grad = PosteriorParams(mean_b = jnp.mean(grads.mean_b, axis=0),\n","                           log_var_b = jnp.mean(grads.log_var_b, axis=0))\n","\n","    print(f\"ELBO[{epoch}] ≈ {elboval}\")\n","    post = tree_map(lambda _post, _grad: _post + step_size * _grad, post, grad)\n","    #print(f\"params = {post}\")\n","    # sample to -compute/evaluate- the ELBO\n","\n","  return post\n",""],"metadata":{"id":"2USyJH82wyhB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# simulate binary outcome\n","N, P = 250, 25\n","prior_var_b = 1e-2\n","\n","seed = 0\n","key = rdm.PRNGKey(seed)\n","key, beta_key, x_key, y_key = rdm.split(key, 4)\n","\n","beta = jnp.sqrt(prior_var_b) * rdm.normal(beta_key, shape=(P,))\n","X = rdm.normal(x_key, (N, P))\n","\n","pred = X @ beta\n","prob = nn.sigmoid(pred)\n","y = rdm.bernoulli(y_key, prob)\n","\n","params = fit(y, X, step_size=0.01, prior_var_b=prior_var_b, num_samples=10)"],"metadata":{"id":"QbCzlIWRP6dU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1743144377386,"user_tz":420,"elapsed":16270,"user":{"displayName":"Tanxin Liu","userId":"08743972115540448245"}},"outputId":"4c78b786-954e-4d9a-87be-bfcacb2cb15f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ELBO[0] ≈ -184.54540376083236\n","ELBO[1] ≈ -175.7925378237437\n","ELBO[2] ≈ -176.099753779408\n","ELBO[3] ≈ -173.94517013973316\n","ELBO[4] ≈ -173.4134425126356\n","ELBO[5] ≈ -172.5357129989426\n","ELBO[6] ≈ -171.5784176964027\n","ELBO[7] ≈ -172.4656387737173\n","ELBO[8] ≈ -170.90120011248692\n","ELBO[9] ≈ -175.01941725066098\n","ELBO[10] ≈ -174.36018326215716\n","ELBO[11] ≈ -172.98281305260588\n","ELBO[12] ≈ -173.9027007199709\n","ELBO[13] ≈ -174.05918948987508\n","ELBO[14] ≈ -174.48104346964143\n","ELBO[15] ≈ -174.82107653110103\n","ELBO[16] ≈ -175.03129071284138\n","ELBO[17] ≈ -174.19863748010906\n","ELBO[18] ≈ -173.98924627599308\n","ELBO[19] ≈ -172.409280886289\n","ELBO[20] ≈ -173.36528208857646\n","ELBO[21] ≈ -173.37780664708146\n","ELBO[22] ≈ -171.61521277299641\n","ELBO[23] ≈ -171.24451708687448\n","ELBO[24] ≈ -172.4470084097542\n","ELBO[25] ≈ -173.5336888594151\n","ELBO[26] ≈ -174.4124669760982\n","ELBO[27] ≈ -172.31565097498822\n","ELBO[28] ≈ -172.27892303974167\n","ELBO[29] ≈ -173.52573341865605\n","ELBO[30] ≈ -174.33788238084207\n","ELBO[31] ≈ -173.60274941791602\n","ELBO[32] ≈ -171.61597690682893\n","ELBO[33] ≈ -171.31223978062792\n","ELBO[34] ≈ -174.88120540713948\n","ELBO[35] ≈ -173.31979916850403\n","ELBO[36] ≈ -175.035470059222\n","ELBO[37] ≈ -174.7557484253441\n","ELBO[38] ≈ -173.88142156268316\n","ELBO[39] ≈ -174.15697435205522\n","ELBO[40] ≈ -170.60845941433746\n","ELBO[41] ≈ -171.2696344141747\n","ELBO[42] ≈ -172.172307790525\n","ELBO[43] ≈ -173.76059789182344\n","ELBO[44] ≈ -172.38318643208618\n","ELBO[45] ≈ -174.11519119113458\n","ELBO[46] ≈ -172.2240826406534\n","ELBO[47] ≈ -172.82003038720308\n","ELBO[48] ≈ -172.9563488054165\n","ELBO[49] ≈ -174.29995304831144\n","ELBO[50] ≈ -172.05880314033737\n","ELBO[51] ≈ -173.17406267351112\n","ELBO[52] ≈ -173.10658871540485\n","ELBO[53] ≈ -172.76574062733016\n","ELBO[54] ≈ -174.43952038171494\n","ELBO[55] ≈ -174.27067949520347\n","ELBO[56] ≈ -174.5926300680322\n","ELBO[57] ≈ -172.21406613868032\n","ELBO[58] ≈ -172.34134801358076\n","ELBO[59] ≈ -169.85686773931752\n","ELBO[60] ≈ -171.9576444263177\n","ELBO[61] ≈ -171.10575787552122\n","ELBO[62] ≈ -172.64149679726214\n","ELBO[63] ≈ -171.45386734084371\n","ELBO[64] ≈ -170.18888184781815\n","ELBO[65] ≈ -172.16483044947086\n","ELBO[66] ≈ -173.12216687624743\n","ELBO[67] ≈ -172.18850064641435\n","ELBO[68] ≈ -172.7531154740662\n","ELBO[69] ≈ -175.34864681417326\n","ELBO[70] ≈ -174.2730382308677\n","ELBO[71] ≈ -174.11237430927508\n","ELBO[72] ≈ -173.93783749514338\n","ELBO[73] ≈ -172.39805471005957\n","ELBO[74] ≈ -170.7725840161084\n","ELBO[75] ≈ -171.88306933796534\n","ELBO[76] ≈ -170.2830062367741\n","ELBO[77] ≈ -172.22583414127158\n","ELBO[78] ≈ -171.54625545811555\n","ELBO[79] ≈ -171.70545426332802\n","ELBO[80] ≈ -171.3500641944954\n","ELBO[81] ≈ -172.8335802234571\n","ELBO[82] ≈ -171.9125699905252\n","ELBO[83] ≈ -172.291091449426\n","ELBO[84] ≈ -174.3669109113638\n","ELBO[85] ≈ -171.0280132835852\n","ELBO[86] ≈ -169.87965482520252\n","ELBO[87] ≈ -170.58190960217817\n","ELBO[88] ≈ -170.78176312205707\n","ELBO[89] ≈ -174.14976026653198\n","ELBO[90] ≈ -171.57148667709288\n","ELBO[91] ≈ -172.64211360692224\n","ELBO[92] ≈ -172.82101708581996\n","ELBO[93] ≈ -171.5548576643824\n","ELBO[94] ≈ -171.83129968072458\n","ELBO[95] ≈ -170.5046091563635\n","ELBO[96] ≈ -174.2571777114043\n","ELBO[97] ≈ -172.191369411676\n","ELBO[98] ≈ -171.4775310675211\n","ELBO[99] ≈ -172.7117388031137\n"]}]}]}